---
title: "County Based Opportunites for Children"
subtitle: "BQOM 2578 | Data Mining"
date: "11/09/2025"
date-format: "full"
author: "Group 8: Anthony Pulleo, Hannah Shernisky, Theresa Wohlever"
editor: source
format:
  pdf:
    toc: true
    toc-depth: 2
    number-sections: false
    mainfont: "Georgia"
    sansfont: "Avenir"
    monofont: "Menlo"
    monofontoptions: "Scale=0.6"
    mathfont: "STIX Two Math"
    pdf-engine: xelatex
---

# Executive Summary

1. With the intention of predicting the Child Opportunity Index (COI), a resource quality measure for healthy development of children our full dataset is aggregated from the following sources: 
    - diversitydatakids.org
    - Census data
    - Urban influence codes, and 
    - 2025 Country Health data 
2. Using our project data we read in the full dataset, clean, wrangle, then prune. The pruned dataset is refined specifically for Random Forest (RF) and Artificial Neural Network (ANN). For the purpose of this homework, we omitted data exploration topics, covered in the final project. The COI score is continuous, therefore we will use regression models through the course of the homework.
3. For random forest, we identified an *optimal mtry at 16*. Running this model, we see that the average number of unhealthy days influences the dependent variable most across the trees. Further, an *OSR of 93, represents a 27% increase in model "accuracy"* over a regression tree.
4. For the neural network, we generated both a zero and one hidden layer model. OSR calculations for both models returned model performance in the *low 80%*. When compared against the Random forest, this is 10-11% less, therefore RF performed better than ANN.

**Group 8: Anthony Pulleo, Hannah Shernisky, Theresa Wohlever**

# Data Preparation
The Child Opportunity Index (COI) measures and maps the quality of resources and conditions like these that matter for children's healthy development in the neighborhoods where they live.

```{r}
#| label: LoadPackages
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

# Clean up the environment before running
rm(list = ls())

#Install Packages
#install.packages("readxl")
#install.packages("tidycensus")

#Establish Libraries
# library(caTools)
# library(ROCR)
library(caret)
library(tidyverse)
library("tidyr") #pivot_longer
library(corrplot)
library(tidyverse)
# library("lm.beta")
library(rpart)
library(rpart.plot)
library(knitr)
library(ggplot2)
library(data.table)
library(rstudioapi)
library(readxl)
library(tidycensus)
library(randomForest)
library(patchwork)
library(caTools)
library(neuralnet)


get_current_file_path <- function() {
  if (!is.null(sys.frames()[[1]]$ofile)) return(normalizePath(sys.frames()[[1]]$ofile))
  if (requireNamespace("rstudioapi", quietly = TRUE) && rstudioapi::isAvailable())
    return(normalizePath(rstudioapi::getSourceEditorContext()$path))
  if (requireNamespace("knitr", quietly = TRUE))
    return(normalizePath(knitr::current_input()))
  return(getwd())
}

working_directory <- dirname(get_current_file_path())
setwd(working_directory)

CSV_base_censusTracts_filename <- "AveChildOppScore_censusTracts_data"
CSV_IN_censusTracts_FILE <- paste(working_directory, "/data_raw/data_COI/", CSV_base_censusTracts_filename, ".csv", sep = "")
CSV_OUT_censusTracts_FILE <- paste(working_directory, "/processed_data/", CSV_base_censusTracts_filename, "_processed.csv", sep = "")

data1 <- read_excel( paste(working_directory, "/data_raw/UrbanInfluenceCodes2024.xlsx", sep = ""), sheet = "Urban Influence Codes 2024")

#2025 County Health Rankings Data
data2 <- read_excel(paste(working_directory, "/data_raw/2025 County Health Rankings Data - v3.xlsx", sep = ""), sheet = "Select Measure Data")

data3 <- read_excel(paste(working_directory,"/data_raw/2025 County Health Rankings Data - v3.xlsx", sep = ""), sheet = "Additional Measure Data")

```

## Importing Data, Cleaning, & Wrangling

```{r}
#| label: ImportData
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

df_censusTracts <- data.table(read.csv(CSV_IN_censusTracts_FILE, stringsAsFactors = TRUE)) 
```

```{r}
#| label: AggregateData
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

df_censusTracts_aggregated <- df_censusTracts %>% select(county_fips,year,pop,r_COI_nat) %>% group_by(county_fips,year) %>% summarize(pop = sum(pop),r_COI_nat=mean(r_COI_nat))


df_censusTracts_aggregated$county_name <- df_censusTracts$county_name[
  match(df_censusTracts_aggregated$county_fips, df_censusTracts$county_fips)
]

df_censusTracts_aggregated$state_name <- df_censusTracts$state_name[
  match(df_censusTracts_aggregated$county_fips, df_censusTracts$county_fips)
]

df_censusTracts_aggregated <- drop_na(df_censusTracts_aggregated)

summary(df_censusTracts_aggregated)
```

The data from diversitydatakids.org contains a series of indices, and does not provide the raw data that was used in the index calculation. The indices are normalized across different areas, like education or housing. We will pull from other datasets to see if factors calculated / assessed by those datasets influence the COI.

These datasets include the Urban Influence Codes from USDA, Census Data as part of the American Community Survey, and the 2025 County Health Rankings Data. Select variables will be appended via a left_join by County FIPS codes.

```{r}
#| label: AdditionalData
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

#Urban Influence Codes
data1 <- data1 %>% select(FIPS,UIC_2024)
data1 <- data1 %>% rename(county_fips = FIPS)
data1$county_fips <- data1$county_fips %>% as.integer()

#census_api_key("901ef7a5f2d76da48c4fe40cdef7fc2c9ad82d00", install = TRUE)
#readRenviron("~/.Renviron")  # Reload your environment so the key is available

#Census Data
income_data <- get_acs(
  geography = "county",
  variables = "B19013_001",  # Median household income
  year = 2022,
  survey = "acs5"
)
income_data$county_fips <- income_data$GEOID %>% as.integer()
income_data <- income_data %>% rename(median_household_income = estimate)
income_data <- income_data %>% select(county_fips,median_household_income)

#2025 County Health Rankings Data
data2_consolidated <- data2 %>% select(
  FIPS,
  avenum_phys_unhealthydays="Average Number of Physically Unhealthy Days",
  percent_lowbirthweight = "% Low Birth Weight",
  avenum_ment_unhealthydays = "Average Number of Mentally Unhealthy Days",
  percent_vaccinated= "% Vaccinated",
  percent_exercise = "% With Access to Exercise Opportunities",
  pcp_ratio = "Primary Care Physicians Ratio",
  mhp_ratio = "Mental Health Provider Ratio",
  dentist_ratio = "Dentist Ratio",
  percent_uninsured = "% Uninsured",
  percent_severehousing = "% Severe Housing Problems",
  percent_broadband = "% Households with Broadband Access",
  )

data2_consolidated$pcp_ratio <- as.integer(substr(data2_consolidated$pcp_ratio, 1, nchar(data2_consolidated$pcp_ratio) - 2))
data2_consolidated$mhp_ratio <- as.integer(substr(data2_consolidated$mhp_ratio, 1, nchar(data2_consolidated$mhp_ratio) - 2))
data2_consolidated$dentist_ratio <- as.integer(substr(data2_consolidated$dentist_ratio, 1, nchar(data2_consolidated$dentist_ratio) - 2))
data2_consolidated$FIPS <- data2_consolidated$FIPS %>% as.integer()
data2_consolidated <- data2_consolidated %>% rename(county_fips = FIPS)



data3_consolidated <- data3 %>% select(
  FIPS,
  life_expectancy = "Life Expectancy",
  percent_adultdiabetes = "% Adults with Diabetes",
  percent_limitedhealthyfood = "% Limited Access to Healthy Foods",
  percent_insufficientsleep = "% Insufficient Sleep",
  percent_reducedlunch = "% Enrolled in Free or Reduced Lunch"
)

data3_consolidated$FIPS <- data3_consolidated$FIPS %>% as.integer()
data3_consolidated <- data3_consolidated %>% rename(county_fips = FIPS)

#Appending all together
df_newDataset <- drop_na(left_join(df_censusTracts_aggregated,data1,by="county_fips"))
df_newDataset <- drop_na(left_join(df_newDataset,income_data,by="county_fips"))
df_newDataset <- drop_na(left_join(df_newDataset,data2_consolidated,by="county_fips"))
df_newDataset <- drop_na(left_join(df_newDataset,data3_consolidated,by="county_fips"))

df_newDataset <- df_newDataset %>% select(-county_name)
df_newDataset <- df_newDataset %>% select(-state_name)


```

# Modeling

## Split data into training and testing

We will deviate slightly from the dataset we will use in our final project for the purpose of this homework. When doing the ANN, we identified a few variables that made the ANN return NaNs, and therefore inhibited our ability to successfully run these models. We will create df_newDataset2 in the code below with variables that allow the ANN to work.

```{r}
df_newDataset2 <- df_newDataset %>% select(county_fips,r_COI_nat,life_expectancy,percent_vaccinated,pop,median_household_income,avenum_phys_unhealthydays,avenum_ment_unhealthydays,percent_lowbirthweight,percent_exercise,pcp_ratio,dentist_ratio,mhp_ratio,percent_uninsured,percent_severehousing,percent_broadband,percent_limitedhealthyfood)

set.seed(123, sample.kind = "Rejection")
spl = sample(nrow(df_newDataset2),0.8*nrow(df_newDataset2))
train.RF = df_newDataset2[spl,]
test.RF = df_newDataset2[-spl,]
```

## Regression Tree

```{r}
regTree = rpart(r_COI_nat ~ ., data = train.RF, method = "anova",
                minbucket = 300, cp = 0.005)

rpart.plot(regTree, digits=-2)
```

## Random Forest

We will start by creating a random forest with similar parameters called for in class, and then we will identify the best mtry.

```{r}
rf1 = randomForest(r_COI_nat~.,data=train.RF,ntree=100,nodesize=50,mtry=7)
```

We see in the plot that after about 20 trees, the model starts to stabilize error around 22, therefore there is not a significant benefit of a model greater than 40, but probably not greater than 20.

```{r}
plot(rf1)
```

```{r}
x = train.RF[,-4] 
y = train.RF$r_COI_nat

tuneRF(x, y, mtryStart = 4, stepFactor = 2, ntreeTry=50, nodesize=50, improve=0.01)
```

The lowest Out-of-Bag error from the dataset and model indicates that an optimal mtry is 16, because this represents the lowest error in the model. Despite the step of 2, we are fairly confident there are not further dips in the OOB Error curve, given the gentle descent of the curve.

We will then generate a "final" Random Forest, with the optimal mtry:

```{r}
rf2 = randomForest(r_COI_nat~.,data=train.RF,ntree=100,nodesize=50,mtry=16)
plot(rf2)
```

```{r}
varImpPlot(rf2)
```

Average number of unhealthy days has the highest impact on inceasing node purity, followed by median household income, and life expectancy

```{r}
#Predictions for the Random Forest
meanCOI = mean(train.RF$r_COI_nat)
pred_rf = predict(rf2, newdata=test.RF)
SSE_rf = sum((test.RF$r_COI_nat - pred_rf)^2)
SST_rf = sum((test.RF$r_COI_nat - meanCOI)^2)
OSR_rf = 1 - SSE_rf/SST_rf
OSR_rf
```

Comparison to Regression Tree

```{r}
# Predictions from Regression Tree
pred = predict(regTree, newdata=test.RF)
SSE = sum((test.RF$r_COI_nat - pred)^2)
SST = sum((test.RF$r_COI_nat - meanCOI)^2)
OSR2 = 1 - SSE/SST
OSR2
```

```{r}
#% Improvement with random forest
OSR_rf/OSR2  -  1 
```

27% improvement in model performance by using random forest

## Artificial Neural Network

```{r}
train.ANN = df_newDataset2[spl,]
test.ANN = df_newDataset2[-spl,]
```

Pre-processing data by scaling it to between 0 and 1:

```{r}
maxVals = apply(train.ANN, 2, max)
minVals = apply(train.ANN, 2, min)
```

```{r}
scaled_train = as.data.frame(scale(train.ANN, center = minVals, 
                                scale = maxVals - minVals))
scaled_test = as.data.frame(scale(test.ANN, center = minVals, 
                                     scale = maxVals - minVals))
```

```{r}
# No Hidden Layer
neuralzero = neuralnet(r_COI_nat~., data= scaled_train, hidden=0,linear.output=TRUE, threshold=0.01, stepmax=20000, lifesign='full', lifesign.step=500)

str(neuralzero)

summary(neuralzero)
plot(neuralzero)
```

```{r}
# One Hidden Layer
neuralone = neuralnet(r_COI_nat~., data= scaled_train, hidden = 1, linear.output=TRUE, threshold=0.01, stepmax=15000, lifesign='full', lifesign.step=500)
summary(neuralone)
plot(neuralone)
```

Calculating OSR2

```{r}
#Neural Zero
neuralzero.test = predict(neuralzero, newdata=scaled_test)
neuralone.test = predict(neuralone,newdata=scaled_test)
summary(neuralzero.test)

m = min(train.ANN$r_COI_nat)
M = max(train.ANN$r_COI_nat)

neuralzeropred.nn = (neuralzero.test * (M - m)) + m
neuralonepred.nn= (neuralone.test * (M - m)) + m

summary(neuralzeropred.nn)

train.mean = mean(train.ANN$r_COI_nat)
SSE.test_zero = sum((neuralzeropred.nn - test.ANN$r_COI_nat)^2)
SSE.test_one = sum((neuralonepred.nn - test.ANN$r_COI_nat)^2)

SST.test = sum((train.mean - test.ANN$r_COI_nat)^2)

OSR2_zero <- 1 - SSE.test_zero/SST.test
OSR2_one <- 1 - SSE.test_one/SST.test

cat("\n \n OSR2 for the Zero Hidden Layer NN is: \n")
OSR2_zero

cat("\n \n OSR2 for the One Hidden Layer NN is: \n")
OSR2_one

```

Comparing with the RF performance:

```{r}
best_nn_OCR = max(OSR2_one,OSR2_zero)

OSR_rf - best_nn_OCR
```

The Random Forest Performs approximately 11% better than the neural network performed. This may be attributable to the fact that the Neural Network as defined above is not fully optimized (as more nodes and layers may have a positive benefit on the overall performance of the model).

# References

https://www.diversitydatakids.org/research-library/child-opportunity-index-30-2023-county-data

https://www.diversitydatakids.org/research-library/research-brief/what-child-opportunity

https://www.ers.usda.gov/data-products/urban-influence-codes


