---
title: "County Based Opportunites for Children"
subtitle: "BQOM 2578 | Data Mining | Homework 6 Unsupervised Learning"
date: "11/23/2025"
date-format: "full"
author: "Group 8: Anthony Pulleo, Hannah Shernisky, Theresa Wohlever"
editor: source
format:
  pdf:
    toc: true
    toc-depth: 2
    number-sections: false
    mainfont: "Georgia"
    sansfont: "Avenir"
    monofont: "Menlo"
    monofontoptions: "Scale=0.6"
    mathfont: "STIX Two Math"
    pdf-engine: xelatex
    fig-width: 5
    fig-height: 7
---

# Executive Summary

1. With the intention of predicting the Child Opportunity Index (COI), a resource quality measure for healthy development of children our full dataset is aggregated from the following sources: 
    - diversitydatakids.org
    - Census data
    - Urban influence codes, and 
    - 2025 Country Health data 
2. Using our project data we read in the full dataset, clean, wrangle, then prune. 
3.Clustering was conducted using **K-means** on a broad set of standardized variables reflecting life expectancy, vaccination rates, income, health outcomes, and more.Feature selection and standardization were appropriately attempted to mitigate scale issues. The number of clusters (K) was selected using a **variance explained/asymptote** (elbow-type) approach, suggesting an optimal K ≈ 6.
4. Cluster analysis performed on the county-level Child Opportunity Index (COI) and health/socioeconomic indicators did **not yield clear, actionable or interpretable groupings**. Key technical and data issues hindered the identification of distinct clusters, substantially limiting potential insights for policy or intervention.
    - **Multiple warnings of non-convergence** in the K-means algorithm indicated instability and unreliable assignment of cluster labels.
    - **High overlap of clusters** in scatterplots across all variable pairs showed a failure of the algorithm to find meaningful group separation.
    - **No clear, distinguishable patterns** among clusters could be identified in terms of key variables such as COI, healthcare access, or economic measures.
    - **Underlying Reasons for Failure:**
      - Continued presence of non-informative or highly correlated features.
      - High dimensionality with relatively little structure.
      - The variety in magnitude/range across input variables, despite attempted standardization, likely contributed to the curse of dimensionality.
      - Insufficient signal or inherent structure in the data to naturally group counties into distinct types.

5. Cluster labels cannot be reliably connected to actionable geographic, socioeconomic, or health profiles.

6. Insights are Gained Despite Unsuccessful Clustering
    - **Current variables or selected data do not naturally segment counties into meaningful subgroups**, at least not in the space defined by K-means and these features.
    - **Clustering is sensitive to feature selection, scaling, and algorithm choice**: future efforts may require
      - More targeted variable selection, perhaps focusing on a smaller, more interpretable set.
      - Dimensionality reduction (e.g., PCA before clustering).
      - Trying alternative clustering algorithms (e.g., hierarchical, DBSCAN).
    - **Domain knowledge is crucial**: Automated clustering alone does not guarantee segments that are useful for intervention or narrative.

## Group 8: Anthony Pulleo, Hannah Shernisky, Theresa Wohlever

# Data Preparation
The Child Opportunity Index (COI) measures and maps the quality of resources and conditions like these that matter for children's healthy development in the neighborhoods where they live.

```{r}
#| label: LoadPackages
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

# Clean up the environment before running
rm(list = ls())

#Establish Libraries
library(tidyverse)
library(corrplot)
library(tidyverse)
library(knitr)
library(ggplot2)
library(rstudioapi)
library(data.table)

library(GGally) ## ggpairs Function
library(readxl) # Read in Excel Files
library(tidycensus) # census data

# Neural Network
library(rpart)
library(rpart.plot)

# Clustering
library(randomForest)
library(neuralnet)
library(dendextend)

# Find Plot asymptote
library(SDLfilter)


#
# GLOBALS
#

seed_this <- sample(42:31337, 1)

#
# Aggregate model stats
#

df_modelCompare <- data.frame(
  Model = c("Linear Regression", "Regression Tree", "Random Forest",  "Artificial Neural Network ONE", "Artificial Neural Network ZERO"),
  OSR2_Phase3Report = c(0.869, 0.757, 0.961, 0.822, NA),
  OSR2_this = c(NA, NA, NA, NA, NA),
  seed_this = c(NA, NA, NA, seed_this, seed_this)
)

```



## Importing Data, Cleaning, & Wrangling

```{r}
#| label: ImportData
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false


# Enable team members to successfully execute locally 
get_current_file_path <- function() {
  if (!is.null(sys.frames()[[1]]$ofile)) return(normalizePath(sys.frames()[[1]]$ofile))
  if (requireNamespace("rstudioapi", quietly = TRUE) && rstudioapi::isAvailable())
    return(normalizePath(rstudioapi::getSourceEditorContext()$path))
  if (requireNamespace("knitr", quietly = TRUE))
    return(normalizePath(knitr::current_input()))
  return(getwd())
}

working_directory <- dirname(get_current_file_path())
setwd(working_directory)

CSV_base_censusTracts_filename <- "AveChildOppScore_censusTracts_data"
CSV_IN_censusTracts_FILE <- paste(working_directory, "/data_raw/data_COI/", CSV_base_censusTracts_filename, ".csv", sep = "")
CSV_OUT_censusTracts_FILE <- paste(working_directory, "/processed_data/", CSV_base_censusTracts_filename, "_processed.csv", sep = "")

df_censusTracts <- data.table(read.csv(CSV_IN_censusTracts_FILE, stringsAsFactors = TRUE)) 
df_censusTracts_og <- df_censusTracts  

df_urbanInfluence <- read_excel( paste(working_directory, "/data_raw/UrbanInfluenceCodes2024.xlsx", sep = ""), sheet = "Urban Influence Codes 2024")
df_urbanInfluence_og <- df_urbanInfluence

#
# 2025 County Health Rankings Data
#
df_CountyHealthSelect <- read_excel(paste(working_directory, "/data_raw/2025 County Health Rankings Data - v3.xlsx", sep = ""), sheet = "Select Measure Data")
df_CountyHealthSelect_og <- df_CountyHealthSelect

df_CountyHealthAddl <- read_excel(paste(working_directory,"/data_raw/2025 County Health Rankings Data - v3.xlsx", sep = ""),  sheet = "Additional Measure Data") #skip = 1,
df_CountyHealthAddl_og <- df_CountyHealthAddl

```

```{r}
#| label: AggregateData
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

df_censusTracts_aggregated <- df_censusTracts %>% select(county_fips,year,pop,r_COI_nat) %>% group_by(county_fips,year) %>% summarize(pop = sum(pop),r_COI_nat=mean(r_COI_nat))


df_censusTracts_aggregated$county_name <- df_censusTracts$county_name[
  match(df_censusTracts_aggregated$county_fips, df_censusTracts$county_fips)
]

df_censusTracts_aggregated$state_name <- df_censusTracts$state_name[
  match(df_censusTracts_aggregated$county_fips, df_censusTracts$county_fips)
]

df_censusTracts_aggregated <- drop_na(df_censusTracts_aggregated)

summary(df_censusTracts_aggregated)
```

The data from diversitydatakids.org contains a series of indices, and does not provide the raw data that was used in the index calculation. The indices are normalized across different areas, like education or housing. We will pull from other datasets to see if factors calculated / assessed by those datasets influence the COI.

These datasets include the Urban Influence Codes from USDA, Census Data as part of the American Community Survey, and the 2025 County Health Rankings Data. Select variables will be appended via a left_join by County FIPS codes.

```{r}
#| label: SelectAndJoinData
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

#
# Urban Influence Codes
#
df_urbanInfluence <- df_urbanInfluence_og %>% select(FIPS,UIC_2024,Population_2020)
df_urbanInfluence$county_fips <- df_urbanInfluence$FIPS %>% as.integer()


#
# Census Data: Median Income
#
census_api_key("901ef7a5f2d76da48c4fe40cdef7fc2c9ad82d00", install = TRUE, overwrite=TRUE)
readRenviron("~/.Renviron")  # Reload R environment so the key is available

df_acs5_income_data <- get_acs(
  geography = "county",
  variables = "B19013_001",  # Median household income
  year = 2022,
  survey = "acs5"
)
df_acs5_income_data$county_fips <- df_acs5_income_data$GEOID %>% as.integer()
df_acs5_income_data <- df_acs5_income_data %>% rename(median_household_income = estimate)
df_acs5_income_data <- df_acs5_income_data %>% select(county_fips,median_household_income)




#
# 2025 County Health Rankings Data
#
### SELECT ###
df_CountyHealthSelect <- df_CountyHealthSelect_og %>% select(
  FIPS,
  avenum_phys_unhealthydays="Average Number of Physically Unhealthy Days",
  percent_lowbirthweight = "% Low Birth Weight",
  avenum_ment_unhealthydays = "Average Number of Mentally Unhealthy Days",
  percent_vaccinated= "% Vaccinated",
  percent_exercise = "% With Access to Exercise Opportunities",
  pcp_ratio = "Primary Care Physicians Ratio",
  mhp_ratio = "Mental Health Provider Ratio",
  dentist_ratio = "Dentist Ratio",
  percent_uninsured = "% Uninsured",
  percent_severehousing = "% Severe Housing Problems",
  percent_broadband = "% Households with Broadband Access",
  )


#
# Medical Accessibility Measures
#
df_CountyHealthSelect$pcp_ratio <- as.integer(
    substr(df_CountyHealthSelect$pcp_ratio, 1, nchar(df_CountyHealthSelect$pcp_ratio) - 2)
    )
df_CountyHealthSelect$mhp_ratio <- as.integer(
  substr(df_CountyHealthSelect$mhp_ratio, 1, nchar(df_CountyHealthSelect$mhp_ratio) - 2)
  )
df_CountyHealthSelect$dentist_ratio <- as.integer(
    substr(df_CountyHealthSelect$dentist_ratio, 1, nchar(df_CountyHealthSelect$dentist_ratio) - 2)
    )
df_CountyHealthSelect$FIPS <- df_CountyHealthSelect$FIPS %>% as.integer()
df_CountyHealthSelect <- df_CountyHealthSelect %>% rename(county_fips = FIPS)


### SELECT ###
df_CountyHealthAddl <- df_CountyHealthAddl_og %>% select(
  FIPS,
  life_expectancy = "Life Expectancy",
  percent_adultdiabetes = "% Adults with Diabetes",
  percent_limitedhealthyfood = "% Limited Access to Healthy Foods",
  percent_insufficientsleep = "% Insufficient Sleep",
  percent_reducedlunch = "% Enrolled in Free or Reduced Lunch",
  percent_feelinglonely = "% feeling lonely"
)

df_CountyHealthAddl$FIPS <- df_CountyHealthAddl$FIPS %>% as.integer()
df_CountyHealthAddl <- df_CountyHealthAddl %>% rename(county_fips = FIPS)



#
# Joining all together
#

df <- drop_na(left_join(df_censusTracts_aggregated,df_urbanInfluence,by="county_fips"))
df <- drop_na(left_join(df,df_acs5_income_data,by="county_fips"))
df <- drop_na(left_join(df,df_CountyHealthSelect,by="county_fips"))
df <- drop_na(left_join(df,df_CountyHealthAddl,by="county_fips"))

df <- df %>% select(-county_name)
df <- df %>% select(-state_name)

df_alljoined <- df ## Save joined state 

```

# Data Exploration

Identify dimensions of interest
```{r}
#| label: SetSelectCols
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false


colsOfInterest = c("county_fips",
  "r_COI_nat",
  "life_expectancy",
  "percent_vaccinated",
  "pop",
  "median_household_income",
  "avenum_phys_unhealthydays",
  "avenum_ment_unhealthydays",
  "percent_lowbirthweight",
  "percent_exercise",
  "pcp_ratio",
  "dentist_ratio",
  "mhp_ratio",
  "percent_uninsured",
  "percent_severehousing",
  "percent_broadband",
  "percent_limitedhealthyfood",
  "percent_feelinglonely"
)

colsOfInterest_scatter = c(
  "life_expectancy",
  "percent_vaccinated",
  "median_household_income",
  "avenum_phys_unhealthydays",
  "avenum_ment_unhealthydays",
  "pcp_ratio",
  "mhp_ratio",
  "percent_uninsured",
  "percent_severehousing",
  "percent_broadband",
  "percent_limitedhealthyfood",
  "percent_feelinglonely"
)
```

```{r}
#| label: DataExloration
#| warning: false
#| echo: true
#| message: false

df$target <- df$r_COI_nat

##
## Visualize target values 
##

# Histogram of target values
target_density <- density(df$target)

# Convert the density estimate to a function
dens_func <- approxfun(target_density$x, target_density$y)

# Use optimize() to find the maximum in a specified interval (choose based on your data)
result <- optimize(dens_func, interval = c(min(df$target), max(df$target)), maximum = TRUE)
local_max_x <- result$maximum     # The x value where local max occurs
local_max_y <- result$objective   # The max density value

#  Create density plot with ggplot2 and add vertical line at max
df_density <- data.frame(x = df$target)
ggplot(df_density, aes(x = df$target)) +
  geom_density(fill = "lightblue", color = "blue", alpha = 0.5) +
  geom_vline(xintercept = local_max_x , color = "red", linetype = "dashed", size = 1) +
  annotate("text", x = local_max_x, y = local_max_y + 0.002, 
    label = sprintf("Max: %.0f", local_max_x), color = "red", angle = 90, vjust = -1, size = 2) +
  labs(title = "Density plot of Child Opportunity Index (COI)", x = "County Child Opportunity Index", y = "Density")


## Make TARGET binary 
target_bin_cutoff <- local_max_x
df$target_bin <- ifelse(df$target < target_bin_cutoff, 0, 1)


scatter_plot_matrix <- ggpairs(
  df[ , colsOfInterest_scatter],
  aes(color = df$target_bin),
  upper = list(continuous = "points"),
  lower = list(continuous = "points"),
  diag  = list(continuous = "densityDiag")
) + 
  theme_minimal() 

print(scatter_plot_matrix)


df_wTarget <- df

df$target_bin <- NULL
df$target <- NULL

```

# Modeling

## Split data into training and testing

We will deviate slightly from the dataset we will use in our final project for the purpose of this homework. When doing the ANN, we identified a few variables that made the ANN return NaNs, and therefore inhibited our ability to successfully run these models. We will create df in the code below with variables that allow the ANN to work.

```{r}
#| label: SelectCols
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

df <- df %>% select(colsOfInterest)
df_model_og <- df

set.seed(seed_this, sample.kind = "Rejection")
spl = sample(nrow(df),0.8*nrow(df))
train.RF = df[spl,]
test.RF = df[-spl,]

```


# Unsupervised Learning 

## K-Means Clustering 
```{r}
#| label: cluster_prep
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

df <- df_model_og

k.values <- 1:50
kpop_iter.max <- 500
kpop_nstart <- 100
kpop_degree <- "optim"  # 5 # 10
kpop_uppper.degree <- 15 # 10 # 25

# 
# colsOfInterest_cluster = c(
#   "life_expectancy",
#   "percent_vaccinated",
#   "median_household_income",
#   "avenum_phys_unhealthydays",
#   "avenum_ment_unhealthydays",
#   "percent_lowbirthweight",
#   "percent_exercise",
#   "pcp_ratio",
#   "dentist_ratio",
#   "mhp_ratio",
#   "percent_uninsured",
#   "percent_severehousing",
#   "percent_broadband",
#   "percent_limitedhealthyfood",
#   "percent_feelinglonely"
# )
# 


## Feature Prune
colsOfInterest_cluster = c(
  "avenum_phys_unhealthydays",
  "median_household_income",
  "percent_uninsured",
  "life_expectancy",
  "percent_broadband",
  "percent_vaccinated"
)


df_cluster <- df %>% select(colsOfInterest_cluster)
df_cluster_og <- df_cluster

# Standardize to mean=0, SD=1 for ALL variables
df_cluster <- as.data.frame(scale(df_cluster))

# Verify standardization worked
print("Means (should be ~0):")
print(colMeans(df_cluster))


print("SDs (should be ~1):")
print(apply(df_cluster, 2, sd))



```

```{r}
#| label: kmeans
#| echo: false
#| message: false
#| results: 'markup'
#| warning: false

iss <- function(k) {
  kmeans(df_cluster,
         centers = k,
         iter.max=kpop_iter.max,
         nstart=kpop_nstart,
         algorithm="Lloyd" )$tot.withinss
}

wss <- function(k) {
  wss <- iss(k)
  return(1 - wss / total_ss)
}


# JAMBU ELBOW
iss_values <- map_dbl(k.values, iss)

# WSS should strictly decrease
cat("\nWSS decreases at each step:\n")
print(diff(iss_values) < 0)  # Should all be TRUE

plot(k.values, iss_values,
     type="b", pch = 19, frame = FALSE, 
     xlab="Number of clusters K",
     ylab="Total intra-clusters sum of squares")


## Total SS
total_ss <- sum((df_cluster- colMeans(df_cluster))^2)
perc_variance <- map_dbl(k.values, wss)

```


```{r}
#| label: kmeans_kpop
#| echo: true
#| message: true
#| results: 'markup'
#| warning: false

k_asym <- function(x,y,kd,kud){
  asymptote(
  x = x,
  y = y,
  degree = kd, # "optim",
  upper.degree = kud,
  # threshold = 0.90,  # Once y reaches 90% of asymptote
  proportional = TRUE,
  estimator = "mean", # "glm",
  ci.level = NULL # We don't need confidence intervals - prevent ERROR: object 'y_lwr' not found
  )
}

k_pop_asymptote_hunter <- k_asym(k.values, perc_variance, kpop_degree, kpop_uppper.degree)
k_pop_asymptote_hunter


plot(k.values, perc_variance,
     type="b", pch = 19, frame = FALSE, 
     xlab="Number of clusters K",
     ylab="Percentage of Variance Explained")
# points(k_pop_asymptote_hunter$min.n, k_pop_asymptote_hunter$h.asymptote, col = "blue", lwd = 2)

k_pop_best_K <- k_pop_asymptote_hunter$min.n

```


```{r}
#| label: kmeans_optimizedClusters
#| echo: true
#| message: true
#| results: 'markup'
#| warning: true


set.seed(seed_this)

## Kpop <- kmeans(df_cluster, k_pop_best_K, iter.max=100, nstart=50)
Kpop <- kmeans(df_cluster,6, iter.max=100, nstart=50)
df$ClusterNumber <- Kpop$cluster


for(col in colsOfInterest_scatter) {
  # Use aes_string or .data pronoun for dynamic column selection
  p <- ggplot(df, aes(x=r_COI_nat, y=.data[[col]], 
                      color=as.factor(ClusterNumber))) +
    geom_point(size=2) +
    labs(x = "COI", y = col, color = "Cluster") +
    ggtitle(paste("Scatterplot:", col, "vs. COI")) + 
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))
  
  print(p)
  
}

 

```

##  Initial K-Means Clustering Analysis

Scatter plots above clearly do nothing to define differentiated groupings nor help assess differences across groups.

#### Problem 1: Complete Convergence Failure
Clustering generated hundreds of “did not converge in 100 iterations” warnings, indicating the algorithm failed to stabilize. This renders all cluster assignments unreliable and non-reproducible. This is likely due to
 - Non-informative variables (county_fips, pop) included in distance calculations
 - No standardization applied despite variables ranging from 0-100 (percentages) to 0-25,000 (ratios)
 - Insufficient iterations (100) for 17-dimensional space
 - High dimensionality creates “curse of dimensionality” effects
 
#### Problem 2: Poor Cluster Separation
Scatter plots show heavily overlapping clusters across all variable pairs, indicating weak separation and low interpretability.This is likely due to
 - Variables on vastly different scales cause large-scale variables to dominate Euclidean distance calculations
 - High dimensionality (17 variables) weakens meaningful distance metrics
 - No cluster quality validation performed (silhouette width, Davies-Bouldin index)

#### Problem 3: Weak Interpretability
Current cluster descriptions lack actionable insights and quantifiable separation metrics.


### K-Means Clustering Analysis
#### Interpretation and Insights from Cluster Analysis

The cluster analysis performed on the county-level Child Opportunity Index (COI) and health/socioeconomic indicators did **not yield clear, actionable or interpretable groupings**. Key technical and data issues hindered the identification of distinct clusters, substantially limiting potential insights for policy or intervention.

##### Description of Clusters and Attempted Interpretation

- Clustering was conducted using **K-means** on a broad set of standardized variables reflecting life expectancy, vaccination rates, income, health outcomes, and more.
- Feature selection and standardization were appropriately attempted to mitigate scale issues.
- The number of clusters (K) was selected using a **variance explained/asymptote** (elbow-type) approach, suggesting an optimal K ≈ 6.

### Key Observations from Cluster Output

- **Multiple warnings of non-convergence** in the K-means algorithm indicated instability and unreliable assignment of cluster labels.
- **High overlap of clusters** in scatterplots across all variable pairs showed a failure of the algorithm to find meaningful group separation.
- **No clear, distinguishable patterns** among clusters could be identified in terms of key variables such as COI, healthcare access, or economic measures.
- **Underlying Reasons for Failure:**
  - Continued presence of non-informative or highly correlated features.
  - High dimensionality with relatively little structure.
  - The variety in magnitude/range across input variables, despite attempted standardization, likely contributed to the curse of dimensionality.
  - Insufficient signal or inherent structure in the data to naturally group counties into distinct types.

### What the Clusters Do NOT Show

- Clusters did **not map clearly to high/low COI, health, wealth, or resource divides**; cluster assignments are heavily overlapped and non-interpretable.
- Cluster labels cannot be reliably connected to actionable geographic, socioeconomic, or health profiles.

### What Insights are Gained Despite Unsuccessful Clustering?

- **Current variables or selected data do not naturally segment counties into meaningful subgroups**, at least not in the space defined by K-means and these features.
- **Clustering is sensitive to feature selection, scaling, and algorithm choice**: future efforts may require
  - More targeted variable selection, perhaps focusing on a smaller, more interpretable set.
  - Dimensionality reduction (e.g., PCA before clustering).
  - Trying alternative clustering algorithms (e.g., hierarchical, DBSCAN).
- **Domain knowledge is crucial**: Automated clustering alone does not guarantee segments that are useful for intervention or narrative.

## Recommendations for Future Clustering Efforts

- Conduct more thorough feature engineering and correlation analysis to reduce redundancy and noise.
- Consider using **dimensionality reduction** to find latent factors before re-applying clustering.
- Evaluate cluster solutions with **external validity metrics** (e.g., silhouette width).
- Triangulate unsupervised clustering with qualitative insights or geographic overlays to assist interpretation.

## Conclusion

The attempted cluster analysis highlights important lessons regarding the **challenges of high-dimensional, mixed-data clustering in real-world policy data**. While the technical execution followed standard procedures, the lack of natural group structure in the data (and technical warnings) resulted in clusters that do **not provide actionable insights or interpretable segments** for understanding or addressing disparities in child opportunity or county health.


# Compare
```{r}
#| label: ConclusionComparison 
#| echo: true
#| message: true
#| results: 'markup'
#| warning: true

print(df_modelCompare)

```

# References

https://www.diversitydatakids.org/research-library/child-opportunity-index-30-2023-county-data

https://www.diversitydatakids.org/research-library/research-brief/what-child-opportunity

https://www.ers.usda.gov/data-products/urban-influence-codes


