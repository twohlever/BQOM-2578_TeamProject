---
title: "County Based Opportunites for Children"
subtitle: "BQOM 2578 | Data Mining | Final Project"
date: "12/04/2025"
date-format: "full"
author: "Group 8: Anthony Pulleo, Hannah Shernisky, Theresa Wohlever"
editor: source
format:
  pdf:
    toc: true
    toc-depth: 2
    number-sections: false
    mainfont: "Georgia"
    sansfont: "Avenir"
    monofont: "Menlo"
    monofontoptions: "Scale=0.6"
    mathfont: "STIX Two Math"
    pdf-engine: xelatex
    fig-width: 5
    fig-height: 7
---

# Executive Summary


## Group 8: Anthony Pulleo, Hannah Shernisky, Theresa Wohlever

# Data Preparation
The Child Opportunity Index (COI) measures and maps the quality of resources and conditions like these that matter for children's healthy development in the neighborhoods where they live.

```{r}
#| label: LoadPackages
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

# Clean up the environment before running
rm(list = ls())

#Establish Libraries
library(tidyverse)
library(corrplot)
library(tidyverse)
library(knitr)
library(ggplot2)
library(rstudioapi)
library(data.table)

library(GGally) ## ggpairs Function
library(readxl) # Read in Excel Files
library(tidycensus) # census data

# Neural Network
library(rpart)
library(rpart.plot)

# Clustering
library(randomForest)
library(neuralnet)
library(dendextend)

# Find Plot asymptote
library(SDLfilter)


#
# GLOBALS
#
target_name <- "percent_feelinglonely"
seed_this <- sample(42:31337, 1)

#
# Aggregate model stats
#


df_modelCompare <- data.frame(
  Model = c("Target Value", "Seed", "Linear Regression", "Regression Tree", "Random Forest",  "Artificial Neural Network ONE", "Artificial Neural Network ZERO"),
  OSR2_iteration_01 = c("percent_feelinglonely", 21813, NA, 0.620719160829882, 0.972006982989319, 0.435072725390803, 0.399148964987301),
  OSR2_iteration_02 = c(NA, NA, NA, NA, NA, NA, NA),
  OSR2_iteration_03 = c(NA, NA, NA, NA, NA, NA, NA),
  OSR2_this = c(target_name, NA, NA,NA,  NA, NA, NA)
)

```



## Importing Data, Cleaning, & Wrangling

```{r}
#| label: ImportData
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false


# Enable team members to successfully execute locally 
get_current_file_path <- function() {
  if (!is.null(sys.frames()[[1]]$ofile)) return(normalizePath(sys.frames()[[1]]$ofile))
  if (requireNamespace("rstudioapi", quietly = TRUE) && rstudioapi::isAvailable())
    return(normalizePath(rstudioapi::getSourceEditorContext()$path))
  if (requireNamespace("knitr", quietly = TRUE))
    return(normalizePath(knitr::current_input()))
  return(getwd())
}

working_directory <- dirname(get_current_file_path())
setwd(working_directory)

CSV_base_censusTracts_filename <- "AveChildOppScore_censusTracts_data"
CSV_IN_censusTracts_FILE <- paste(working_directory, "/data_raw/data_COI/", CSV_base_censusTracts_filename, ".csv", sep = "")
CSV_OUT_censusTracts_FILE <- paste(working_directory, "/processed_data/", CSV_base_censusTracts_filename, "_processed.csv", sep = "")

df_censusTracts <- data.table(read.csv(CSV_IN_censusTracts_FILE, stringsAsFactors = TRUE)) 
df_censusTracts_og <- df_censusTracts  

df_urbanInfluence <- read_excel( paste(working_directory, "/data_raw/UrbanInfluenceCodes2024.xlsx", sep = ""), sheet = "Urban Influence Codes 2024")
df_urbanInfluence_og <- df_urbanInfluence

#
# 2025 County Health Rankings Data
#
df_CountyHealthSelect <- read_excel(paste(working_directory, "/data_raw/2025 County Health Rankings Data - v3.xlsx", sep = ""), sheet = "Select Measure Data")
df_CountyHealthSelect_og <- df_CountyHealthSelect

df_CountyHealthAddl <- read_excel(paste(working_directory,"/data_raw/2025 County Health Rankings Data - v3.xlsx", sep = ""),  sheet = "Additional Measure Data") #skip = 1,
df_CountyHealthAddl_og <- df_CountyHealthAddl

```

```{r}
#| label: AggregateData
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

df_censusTracts_aggregated <- df_censusTracts %>% select(county_fips,year,pop,r_COI_nat) %>% group_by(county_fips,year) %>% summarize(pop = sum(pop),r_COI_nat=mean(r_COI_nat))


df_censusTracts_aggregated$county_name <- df_censusTracts$county_name[
  match(df_censusTracts_aggregated$county_fips, df_censusTracts$county_fips)
]

df_censusTracts_aggregated$state_name <- df_censusTracts$state_name[
  match(df_censusTracts_aggregated$county_fips, df_censusTracts$county_fips)
]

df_censusTracts_aggregated <- drop_na(df_censusTracts_aggregated)

summary(df_censusTracts_aggregated)
```

The data from diversitydatakids.org contains a series of indices, and does not provide the raw data that was used in the index calculation. The indices are normalized across different areas, like education or housing. We will pull from other datasets to see if factors calculated / assessed by those datasets influence the COI.

These datasets include the Urban Influence Codes from USDA, Census Data as part of the American Community Survey, and the 2025 County Health Rankings Data. Select variables will be appended via a left_join by County FIPS codes.

```{r}
#| label: SelectAndJoinData
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

#
# Urban Influence Codes
#
df_urbanInfluence <- df_urbanInfluence_og %>% select(FIPS,UIC_2024,Population_2020)
df_urbanInfluence$county_fips <- df_urbanInfluence$FIPS %>% as.integer()


#
# Census Data: Median Income
#
census_api_key("901ef7a5f2d76da48c4fe40cdef7fc2c9ad82d00", install = TRUE, overwrite=TRUE)
readRenviron("~/.Renviron")  # Reload R environment so the key is available

df_acs5_income_data <- get_acs(
  geography = "county",
  variables = "B19013_001",  # Median household income
  year = 2022,
  survey = "acs5"
)
df_acs5_income_data$county_fips <- df_acs5_income_data$GEOID %>% as.integer()
df_acs5_income_data <- df_acs5_income_data %>% rename(median_household_income = estimate)
df_acs5_income_data <- df_acs5_income_data %>% select(county_fips,median_household_income)




#
# 2025 County Health Rankings Data
#
### SELECT ###
df_CountyHealthSelect <- df_CountyHealthSelect_og %>% select(
  FIPS,
  avenum_phys_unhealthydays="Average Number of Physically Unhealthy Days",
  percent_lowbirthweight = "% Low Birth Weight",
  avenum_ment_unhealthydays = "Average Number of Mentally Unhealthy Days",
  ment_health_provder_rate = "Mental Health Provider Rate",
  percent_vaccinated= "% Vaccinated",
  percent_exercise = "% With Access to Exercise Opportunities",
  preventable_hospitalization_rate = "Preventable Hospitalization Rate",
  pcp_ratio = "Primary Care Physicians Ratio",
  mhp_ratio = "Mental Health Provider Ratio",
  dentist_ratio = "Dentist Ratio",
  percent_uninsured = "% Uninsured",
  percent_severehousing = "% Severe Housing Problems",
  percent_broadband = "% Households with Broadband Access",
  overcrowding = "Overcrowding",
  long_commute_drives_alone = "% Long Commute - Drives Alone",
  income_ratio = "Income Ratio",
  injury_death_rate = "Injury Death Rate"
  )


#
# Medical Accessibility Measures
#
df_CountyHealthSelect$pcp_ratio <- as.integer(
    substr(df_CountyHealthSelect$pcp_ratio, 1, nchar(df_CountyHealthSelect$pcp_ratio) - 2)
    )
df_CountyHealthSelect$mhp_ratio <- as.integer(
  substr(df_CountyHealthSelect$mhp_ratio, 1, nchar(df_CountyHealthSelect$mhp_ratio) - 2)
  )
df_CountyHealthSelect$dentist_ratio <- as.integer(
    substr(df_CountyHealthSelect$dentist_ratio, 1, nchar(df_CountyHealthSelect$dentist_ratio) - 2)
    )
df_CountyHealthSelect$FIPS <- df_CountyHealthSelect$FIPS %>% as.integer()
df_CountyHealthSelect <- df_CountyHealthSelect %>% rename(county_fips = FIPS)

##
### SELECT Columns from Raw Datasets
##
df_CountyHealthAddl <- df_CountyHealthAddl_og %>% select(
  FIPS,
  life_expectancy = "Life Expectancy",
  percent_adultdiabetes = "% Adults with Diabetes",
  percent_limitedhealthyfood = "% Limited Access to Healthy Foods",
  percent_insufficientsleep = "% Insufficient Sleep",
  percent_reducedlunch = "% Enrolled in Free or Reduced Lunch",
  percent_feelinglonely = "% feeling lonely"
)

df_CountyHealthAddl$FIPS <- df_CountyHealthAddl$FIPS %>% as.integer()
df_CountyHealthAddl <- df_CountyHealthAddl %>% rename(county_fips = FIPS)



#
# Joining all data sets together
#
df <- drop_na(left_join(df_censusTracts_aggregated,df_urbanInfluence,by="county_fips"))
df <- drop_na(left_join(df,df_acs5_income_data,by="county_fips"))
df <- drop_na(left_join(df,df_CountyHealthSelect,by="county_fips"))
df <- drop_na(left_join(df,df_CountyHealthAddl,by="county_fips"))

df <- df %>% select(-county_name)
df <- df %>% select(-state_name)

# Force unique row for each county+year
df <- df %>% distinct(county_fips, year, .keep_all = TRUE)

df_alljoined <- df ## Save joined state 

summary(df)

```

# Data Exploration

Identify dimensions of interest
```{r}
#| label: SetSelectCols
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false


colsOfInterest = c( "avenum_ment_unhealthydays",
  "avenum_phys_unhealthydays",
  "dentist_ratio",
  "income_ratio",
  "injury_death_rate",
  "long_commute_drives_alone",
  "median_household_income",
  "ment_health_provder_rate",
  "mhp_ratio",
  "overcrowding",
  "pcp_ratio",
  "percent_broadband",
  "percent_exercise",
  "percent_feelinglonely",
  "percent_limitedhealthyfood",
  "percent_lowbirthweight",
  "percent_severehousing",
  "percent_uninsured",
  "percent_vaccinated",
  "r_COI_nat",
  "county_fips"
#  "life_expectancy",
#  "pop"
)

```

```{r}
#| label: DataExloration
#| warning: false
#| echo: true
#| message: false

df <- df_alljoined 

#
# COI
#
# Histogram of target values
coi_density <- density(df$r_COI_nat)

# Convert the density estimate to a function
coi_dens_func <- approxfun(coi_density$x, coi_density$y)

# Use optimize() to find the maximum in a specified interval (choose based on your data)
coi_result <- optimize(coi_dens_func, interval = c(min(df$r_COI_nat), max(df$r_COI_nat)), maximum = TRUE)
coi_local_max_x <- coi_result$maximum     # The x value where local max occurs
coi_local_max_y <- coi_result$objective   # The max density value

## Make COI binary 
coi_bin_cutoff <- coi_local_max_x
df$coi_bin <- ifelse(df$r_COI_nat < coi_bin_cutoff, 0, 1)




###
### TARGET
###

# df$target <- df$r_COI_nat
df$target <- df[[target_name]]
df[[target_name]] <- NULL
colsOfInterest <- colsOfInterest[!(colsOfInterest %in% target_name)]
colsOfInterest <- c(colsOfInterest, "target")

##
## Visualize target values 
##

# Histogram of target values
target_density <- density(df$target)

# Convert the density estimate to a function
dens_func <- approxfun(target_density$x, target_density$y)

# Use optimize() to find the maximum in a specified interval (choose based on your data)
result <- optimize(dens_func, interval = c(min(df$target), max(df$target)), maximum = TRUE)
local_max_x <- result$maximum     # The x value where local max occurs
local_max_y <- result$objective   # The max density value

#  Create density plot with ggplot2 and add vertical line at max
df_density <- data.frame(x = df$target)
ggplot(df_density, aes(x = df$target)) +
  geom_density(fill = "lightblue", color = "blue", alpha = 0.5) +
  geom_vline(xintercept = local_max_x , color = "red", linetype = "dashed", size = 1) +
  annotate("text", x = local_max_x, y = local_max_y + 0.002, 
    label = sprintf("Max: %.0f", local_max_x), color = "red", angle = 90, vjust = -1, size = 2) +
  labs(title = paste("Density plot of ", target_name), x = target_name, y = "Density")


## Make TARGET binary 
target_bin_cutoff <- local_max_x
df$target_bin <- ifelse(df$target < target_bin_cutoff, 0, 1)


## Reasonably sized scatter plots
bySeq <- 4
modSeq <- length(colsOfInterest) %% bySeq
cols2scatter <- colsOfInterest[!(colsOfInterest %in% "target")]
scatterSeq <- seq.int(1, length(colsOfInterest), bySeq)

for(c in scatterSeq)
{
  if(c == scatterSeq[length(scatterSeq)]){bySeq <- bySeq + modSeq}
  cols2Plot <- unique(c(colsOfInterest[c:(c+bySeq)], "target"))
  cols2Plot <- cols2Plot[!is.na(cols2Plot)]
  if(2 > length(cols2Plot)){next}
  
  scatter_plot_matrix <- ggpairs(
    df[ , cols2Plot],
    aes(color = df$coi_bin),
    upper = list(continuous = "points"),
    lower = list(continuous = "points"),
    diag  = list(continuous = "densityDiag")
  ) + 
    theme_minimal() 
 
  print(scatter_plot_matrix)
}

df_wTargetBin <- df
df$target_bin <- NULL


```


```{r}
#| label: CorrelationMatrix
#| echo: true
#| message: true
#| warning: false
## Prep for correlation
df_cor <- df

cor_mat <- cor(df %>% select(where(is.numeric)))
cor_threshold <- 0
cor_threshold_count <- 2

cols_above_threshold <- which( colSums(abs(cor_mat) > cor_threshold, na.rm = TRUE) >= cor_threshold_count)

df <- subset(df, select = colnames(cor_mat)[cols_above_threshold] )
cor_mat <- cor(df %>% select(where(is.numeric)))

cat(paste(colnames(cor_mat)[cols_above_threshold], collapse = "\n"))

cor_mat_plot <- round(cor_mat, 2)
cor_mat_plot[is.na(cor_mat_plot)] <- 0 # Replace all NA values with zero
corrplot(cor_mat_plot, 
  method="square",
  type="upper",
  order="AOE", 
  tl.col="darkgrey",
  tl.cex = 0.7,      # label size
  cl.align.text = "r",
  cl.cex = 0.5,   # legend text
  diag=FALSE, 
  number.cex=0.6)


```





# Modeling

## Split data into training and testing

We will deviate slightly from the dataset we will use in our final project for the purpose of this homework. When doing the ANN, we identified a few variables that made the ANN return NaNs, and therefore inhibited our ability to successfully run these models. We will create df in the code below with variables that allow the ANN to work.


```{r}
#| label: SelectCols
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

df <- df %>% select(colsOfInterest)
df_model_og <- df

set.seed(seed_this, sample.kind = "Rejection")
spl = sample(nrow(df),0.8*nrow(df))
train.RF = df[spl,]
test.RF = df[-spl,]

df_modelCompare$OSR2_this[ df_modelCompare$Model == "Seed"] <- seed_this

```

## Regression Tree

```{r}
#| label: RegTree
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

regTree = rpart(target ~ ., 
                data = train.RF, 
                method = "anova",
                minbucket = 30, 
                cp = 0.005)

rpart.plot(regTree, digits=-2)
```

## Random Forest

We will start by creating a random forest then identify the best mtry.

```{r}
#| label: RandomForest
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

mtry <- 7

rf1 = randomForest(target ~ .,  
                   data=train.RF,
                   ntree=100,
                   nodesize=50,
                   mtry=mtry)
plot(rf1)


x <- train.RF %>% select(-target)
y <- train.RF$target


rf2 <- tuneRF(x, y, mtryStart = mtry, stepFactor = 1, ntreeTry=50, nodesize=50, improve=0.01, trace=TRUE, doBest = TRUE)
plot(rf2)
varImpPlot(rf2)
rf2_pdat <- varImpPlot(rf2)

```

```{r}
#| label: RandomForestPredictions
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

# Predictions for the Random Forest
meanCOI = mean(train.RF$target)
pred_rf = predict(rf2, newdata=test.RF)
SSE_rf = sum((test.RF$target - pred_rf)^2)
SST_rf = sum((test.RF$target - meanCOI)^2)
OSR_rf = 1 - SSE_rf/SST_rf
OSR_rf


df_modelCompare$OSR2_this[ df_modelCompare$Model == "Random Forest"] <- OSR_rf

```

Comparison to Regression Tree

```{r}
#| label: RFvsRT
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

# Predictions from Regression Tree
pred = predict(regTree, newdata=test.RF)
SSE = sum((test.RF$target - pred)^2)
SST = sum((test.RF$target - meanCOI)^2)
OSR2 = 1 - SSE/SST
OSR2

df_modelCompare$OSR2_this[ df_modelCompare$Model == "Regression Tree"] <- OSR2

#% Improvement with random forest
RFImprovement <- OSR_rf/OSR2  -  1 

print(
  paste(
    round(100*RFImprovement, digits = 0),
    "% improvement in model performance with Random Forest over Regression Tree.")
)
```



## Artificial Neural Network

```{r}
#| label: ANN
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

train.ANN = df[spl,]
test.ANN = df[-spl,]


# Protect scaling from zero range; remove constant columns
maxVals <- apply(train.ANN, 2, max, na.rm = TRUE)
minVals <- apply(train.ANN, 2, min, na.rm = TRUE)
rangeVals <- pmax(maxVals - minVals, 1e-9)  # avoid zero

scaled_train <- as.data.frame(scale(train.ANN, center = minVals, scale = rangeVals))
scaled_test  <- as.data.frame(scale(test.ANN,  center = minVals, scale = rangeVals))

# Drop constant predictors before scaling
const_cols <- which(maxVals == minVals)
if (length(const_cols) > 0) {
  train.ANN <- train.ANN[ , -const_cols, drop = FALSE]
  test.ANN  <- test.ANN[ , -const_cols, drop = FALSE]
}


# No Hidden Layer
neuralzero <- neuralnet(
  target ~ .,
  data          = scaled_train,
  hidden        = 0,
  linear.output = TRUE,
  threshold     = 0.01,
  stepmax       = 20000,
  lifesign      = "full",
  lifesign.step = 500
)


# plot(neuralzero)
# Plotting commented out due to error:
## Error in grid.Call.graphics(C_setviewport, vp, TRUE) : 
##  non-finite location and/or size for viewport

str(neuralzero)
summary(neuralzero)


# One Hidden Layer
neuralone = neuralnet(target~., 
  data= scaled_train, 
  hidden = 1, 
  linear.output=TRUE, 
  threshold=0.01, 
  stepmax=15000, 
  lifesign='full', 
  lifesign.step=500
)
summary(neuralone)
plot(neuralone)
```



```{r}
#| label: ANN_Pred
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false


# Neural Zero
neuralzero.test = predict(neuralzero, newdata=scaled_test)
neuralone.test = predict(neuralone,newdata=scaled_test)
summary(neuralzero.test)

m = min(train.ANN$target)
M = max(train.ANN$target)

neuralzeropred.nn = (neuralzero.test * (M - m)) + m
neuralonepred.nn= (neuralone.test * (M - m)) + m

summary(neuralzeropred.nn)

train.mean = mean(train.ANN$target)
SSE.test_zero = sum((neuralzeropred.nn - test.ANN$target)^2)
SSE.test_one = sum((neuralonepred.nn - test.ANN$target)^2)

SST.test = sum((train.mean - test.ANN$target)^2)

OSR2_zero <- 1 - SSE.test_zero/SST.test
OSR2_one <- 1 - SSE.test_one/SST.test

cat("\n \n OSR2 for the Zero Hidden Layer NN is: \n")
OSR2_zero

cat("\n \n OSR2 for the One Hidden Layer NN is: \n")
OSR2_one


## "Linear Regression", "Regression Tree", "Random Forest",  "Artificial Neural Network ONE", "Artificial Neural Network ZERO"
df_modelCompare$OSR2_this[ df_modelCompare$Model == "Artificial Neural Network ONE"] <- OSR2_one
df_modelCompare$OSR2_this[ df_modelCompare$Model == "Artificial Neural Network ZERO"] <- OSR2_zero


```

Comparing with the RF performance:

```{r}
#| label: ANNvsRTF
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

best_nn_OCR = max(OSR2_one,OSR2_zero)

OSR_rf - best_nn_OCR
```




# Unsupervised Learning 

## K-Means Clustering 
```{r}
#| label: cluster_prep
#| echo: false
#| message: false
#| results: 'hide'
#| warning: false

df <- df_model_og

k.values <- 1:50
kpop_iter.max <- 500
kpop_nstart <- 100
kpop_degree <- "optim"  # 5 # 10
kpop_uppper.degree <- 15 # 10 # 25


## Feature Prune based on RF node purity
top5val <- (sort(rf2_pdat, decreasing = TRUE))[5] 
colsOfInterest_cluster <- rownames(rf2_pdat)[rf2_pdat >= top5val]


df_cluster <- df %>% select(colsOfInterest_cluster)
df_cluster_og <- df_cluster

# Standardize to mean=0, SD=1 for ALL variables
df_cluster <- as.data.frame(scale(df_cluster))

# Verify standardization worked
print("Means (should be ~0):")
print(colMeans(df_cluster))


print("SDs (should be ~1):")
print(apply(df_cluster, 2, sd))



```

```{r}
#| label: kmeans
#| echo: false
#| message: false
#| results: 'markup'
#| warning: false

iss <- function(k) {
  kmeans(df_cluster,
         centers = k,
         iter.max=kpop_iter.max,
         nstart=kpop_nstart,
         algorithm="Lloyd" )$tot.withinss
}

wss <- function(k) {
  wss <- iss(k)
  return(1 - wss / total_ss)
}


# JAMBU ELBOW
iss_values <- map_dbl(k.values, iss)

# WSS should strictly decrease
cat("\nWSS decreases at each step:\n")
print(diff(iss_values) < 0)  # Should all be TRUE

plot(k.values, iss_values,
     type="b", pch = 19, frame = FALSE, 
     xlab="Number of clusters K",
     ylab="Total intra-clusters sum of squares")


## Total SS
total_ss <- sum((df_cluster- colMeans(df_cluster))^2)
perc_variance <- map_dbl(k.values, wss)

```


```{r}
#| label: kmeans_kpop
#| echo: true
#| message: true
#| results: 'markup'
#| warning: false

k_asym <- function(x,y,kd,kud){
  asymptote(
  x = x,
  y = y,
  degree = kd, # "optim",
  upper.degree = kud,
  # threshold = 0.90,  # Once y reaches 90% of asymptote
  proportional = TRUE,
  estimator = "mean", # "glm",
  ci.level = NULL # We don't need confidence intervals - prevent ERROR: object 'y_lwr' not found
  )
}

k_pop_asymptote_hunter <- k_asym(k.values, perc_variance, kpop_degree, kpop_uppper.degree)
k_pop_asymptote_hunter


plot(k.values, perc_variance,
     type="b", pch = 19, frame = FALSE, 
     xlab="Number of clusters K",
     ylab="Percentage of Variance Explained")
# points(k_pop_asymptote_hunter$min.n, k_pop_asymptote_hunter$h.asymptote, col = "blue", lwd = 2)

k_pop_best_K <- k_pop_asymptote_hunter$min.n

```


```{r}
#| label: kmeans_optimizedClusters
#| echo: true
#| message: true
#| results: 'markup'
#| warning: true


set.seed(seed_this)

## Kpop <- kmeans(df_cluster, k_pop_best_K, iter.max=100, nstart=50)
Kpop <- kmeans(df_cluster,6, iter.max=100, nstart=50)
df$ClusterNumber <- Kpop$cluster


for(col in colsOfInterest) {
  # Use aes_string or .data pronoun for dynamic column selection
  p <- ggplot(df, aes(x=target, y=.data[[col]], 
                      color=as.factor(ClusterNumber))) +
    geom_point(size=2) +
    labs(x = "COI", y = col, color = "Cluster") +
    ggtitle(paste("Scatterplot:", col, "vs. COI")) + 
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))
  
  print(p)
  
}

 

```


# Compare
```{r}
#| label: ConclusionComparison 
#| echo: true
#| message: true
#| results: 'markup'
#| warning: true

print(df_modelCompare)

```

# References

https://www.diversitydatakids.org/research-library/child-opportunity-index-30-2023-county-data

https://www.diversitydatakids.org/research-library/research-brief/what-child-opportunity

https://www.ers.usda.gov/data-products/urban-influence-codes


